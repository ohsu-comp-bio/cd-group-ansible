# Copyright 2016(c) The Ontario Institute for Cancer Research. All rights reserved.

hdfs_cloudera_distribution: "cdh5.3.1"
hdfs_conf_dir: "/etc/hadoop/conf"
hdfs_namenode: False
# get the private ipv4 address from the dynamic inventory.  Can also use
# hostvars[lookup('inventory_hostnames', 'dcc-hdfs-namenode')].openstack.private_v4
# hostvars[lookup('inventory_hostnames', 'dcc-hdfs-namenode')].ansible_all_ipv4_addresses[0]
#
hdfs_namenode_host: "dcc-hdfs-namenode"
hdfs_namenode_port: 8020
hdfs_disks: [{ mount_point: '/dfs/data', device: '/dev/sda1' }]

hdfs_core_properties:
  - { name: "fs.defaultFS", value: "hdfs://{{ hdfs_namenode_host }}:{{ hdfs_namenode_port }}" }
hdfs_namenode_properties:
  # need to add user submitting job to the "hadoop" group, or turn filesystem
  # security off.
  # https://hadoop.apache.org/docs/r1.2.1/hdfs_permissions_guide.html#Configuration+Parameters
  - { name: "dfs.permissions.superusergroup", value: "hadoop" }
  - { name: "dfs.namenode.name.dir", value: "/media/persistent0" }
hdfs_datanode_properties:
  - { name: "dfs.permissions.superusergroup", value: "hadoop" }
  - { name: "dfs.datanode.data.dir", value: "{{ hdfs_disks | map(attribute='mount_point') | join(',') }}" }
jdk_home: /usr/lib/jvm/java-8-oracle/

