# Copyright 2016(c) The Ontario Institute for Cancer Research. All rights reserved.

hdfs_cloudera_distribution: "cdh5.3.1"
hdfs_conf_dir: "/etc/hadoop/conf"
hdfs_lib_dir: "/usr/lib/hadoop/lib"
hdfs_namenode: False
hdfs_namenode_host: "dcc-etl-2"
hdfs_namenode_port: 8020
hdfs_disks: [{ mount_point: '/dfs/data', device: '/dev/sda1' }]

hdfs_core_properties:
  - { name: "fs.defaultFS", value: "hdfs://{{ hdfs_namenode_host }}:{{ hdfs_namenode_port }}" }
hdfs_namenode_properties:
  # need to add user submitting job to the "hadoop" group, or turn filesystem
  # security off.
  # https://hadoop.apache.org/docs/r1.2.1/hdfs_permissions_guide.html#Configuration+Parameters
  - { name: "dfs.blocksize", value: 134217728 } # 128*1024*1024
  - { name: "dfs.permissions.superusergroup", value: "hadoop" }
  - { name: "dfs.namenode.name.dir", value: "/media/persistent0" }
  - { name: "dfs.replication", value: "1" }
  # set handler threads to min(20*log2(cluster size), 200)
  # https://community.hortonworks.com/questions/63511/namenode-handler-count.html
  - { name: "dfs.namenode.handler.count", value: 70 }
  - { name: "dfs.client.socket-timeout", value: 120000 } # default is 60000
jdk_home: /usr/lib/jvm/java-8-oracle/
hdfs_datanode_properties:
  - { name: "dfs.permissions.superusergroup", value: "hadoop" }
  - { name: "dfs.datanode.data.dir", value: "{{ hdfs_disks | map(attribute='mount_point') | join(',') }}" }
  - { name: "dfs.datanode.max.transfer.threads", value: "5000" }
jdk_home: /usr/lib/jvm/java-8-oracle/

